{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import cross_validation, metrics \n",
    "from sklearn.grid_search import GridSearchCV \n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kagTrainDat = pd.read_csv('~/Documents/git/DataMining/train.csv')\n",
    "kagTestDat = pd.read_csv('~/Documents/git/DataMining/test.csv')\n",
    "\n",
    "y_train = kagTrainDat['ACTION']\n",
    "X_train = kagTrainDat.ix[:, kagTrainDat.columns != 'ACTION']\n",
    "\n",
    "X_test = kagTestDat.ix[:, kagTestDat.columns != 'id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = xgb.XGBClassifier(nthread=multiprocessing.cpu_count(),\n",
    "                        n_estimators=1500,\n",
    "                        max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until cv error hasn't decreased in 100 rounds.\nC:\\Program Files\\Python35\\lib\\site-packages\\xgboost-0.4-py3.5.egg\\xgboost\\training.py:270: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n  idset = [randidx[(i * kstep): min(len(randidx), (i + 1) * kstep)] for i in range(nfold)]\n[0]\tcv-test-auc:0.624009+0.009532923811716922\tcv-train-auc:0.6529736+0.007525845031622675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[500]\tcv-test-auc:0.8412712000000001+0.008099015678463647\tcv-train-auc:0.9801028+0.0010994886811604811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping. Best iteration:\n[678] cv-mean:0.8453262\tcv-std:0.010205374376278427\n"
     ]
    }
   ],
   "source": [
    "xg_train = xgb.DMatrix(X_train.values, label=y_train.values)\n",
    "cv_result = xgb.cv(gbm.get_params(), xg_train,\n",
    "                   num_boost_round=gbm.get_params()['n_estimators'],\n",
    "                   nfold=5, metrics=\"auc\",\n",
    "                   early_stopping_rounds=100,\n",
    "                   verbose_eval=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(estimator, test_parameters):\n",
    "    return GridSearchCV(estimator=estimator, param_grid=test_parameters,\n",
    "                        scoring='roc_auc', n_jobs=multiprocessing.cpu_count(),\n",
    "                        iid=False, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.82604, std: 0.01384, params: {'min_child_weight': 1, 'max_depth': 3},\n  mean: 0.82530, std: 0.01366, params: {'min_child_weight': 3, 'max_depth': 3},\n  mean: 0.82516, std: 0.01200, params: {'min_child_weight': 5, 'max_depth': 3},\n  mean: 0.84940, std: 0.01306, params: {'min_child_weight': 1, 'max_depth': 5},\n  mean: 0.84612, std: 0.01357, params: {'min_child_weight': 3, 'max_depth': 5},\n  mean: 0.84293, std: 0.01143, params: {'min_child_weight': 5, 'max_depth': 5},\n  mean: 0.85233, std: 0.01365, params: {'min_child_weight': 1, 'max_depth': 7},\n  mean: 0.85222, std: 0.01283, params: {'min_child_weight': 3, 'max_depth': 7},\n  mean: 0.84868, std: 0.01340, params: {'min_child_weight': 5, 'max_depth': 7}],\n {'max_depth': 7, 'min_child_weight': 1},\n 0.85232618392450132)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm2 = xgb.XGBClassifier(nthread=multiprocessing.cpu_count(),\n",
    "                         n_estimators=678,\n",
    "                         max_depth=5)\n",
    "\n",
    "param_test1 = {\n",
    "    'max_depth': list(range(3, 9, 2)),\n",
    "    'min_child_weight': list(range(1, 6, 2))\n",
    "}\n",
    "\n",
    "grid_search1 = grid_search(gbm2, param_test1)\n",
    "\n",
    "grid_search1.fit(X_train, y_train)\n",
    "grid_search1.grid_scores_, grid_search1.best_params_, grid_search1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.85081, std: 0.01430, params: {'min_child_weight': 1, 'max_depth': 6},\n  mean: 0.85233, std: 0.01365, params: {'min_child_weight': 1, 'max_depth': 7}],\n {'max_depth': 7, 'min_child_weight': 1},\n 0.85232618392450132)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test2 = {\n",
    "    'max_depth': list(range(6, 8, 1)),\n",
    "    'min_child_weight': list(range(1, 2, 1))\n",
    "}\n",
    "\n",
    "grid_search2 = grid_search(gbm2, param_test2)\n",
    "\n",
    "grid_search2.fit(X_train, y_train)\n",
    "grid_search2.grid_scores_, grid_search2.best_params_, grid_search2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until cv error hasn't decreased in 100 rounds.\nC:\\Program Files\\Python35\\lib\\site-packages\\xgboost-0.4-py3.5.egg\\xgboost\\training.py:270: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n  idset = [randidx[(i * kstep): min(len(randidx), (i + 1) * kstep)] for i in range(nfold)]\n[0]\tcv-test-auc:0.6421134000000001+0.012265641452447565\tcv-train-auc:0.6841790000000001+0.01028755693058367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping. Best iteration:\n[279] cv-mean:0.8436060000000001\tcv-std:0.006814960924319401\n"
     ]
    }
   ],
   "source": [
    "gbm_test = xgb.XGBClassifier(nthread=multiprocessing.cpu_count(),\n",
    "                            n_estimators=1500,\n",
    "                            max_depth=7,\n",
    "                            min_child_weight=1)\n",
    "\n",
    "xg_train2 = xgb.DMatrix(X_train.values, label=y_train.values)\n",
    "cv_result2 = xgb.cv(gbm_test.get_params(), xg_train,\n",
    "                    num_boost_round=gbm.get_params()['n_estimators'],\n",
    "                    nfold=5, metrics=\"auc\",\n",
    "                    early_stopping_rounds=100,\n",
    "                    verbose_eval=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score (Train): 0.986453\n"
     ]
    }
   ],
   "source": [
    "gbm_test = xgb.XGBClassifier(nthread=multiprocessing.cpu_count(),\n",
    "                            n_estimators=279,\n",
    "                            max_depth=7,\n",
    "                            min_child_weight=1)\n",
    "\n",
    "# Fit the algorithm on the data\n",
    "gbm_test.fit(X_train, y_train, eval_metric='auc')\n",
    "        \n",
    "# Predict training set:\n",
    "train_predict_prob = gbm_test.predict_proba(X_train)[:, 1]\n",
    "\n",
    "print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(y_train, train_predict_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.84969, std: 0.01399, params: {'gamma': 0.0},\n  mean: 0.84780, std: 0.01541, params: {'gamma': 0.1},\n  mean: 0.84991, std: 0.01364, params: {'gamma': 0.2},\n  mean: 0.84973, std: 0.01353, params: {'gamma': 0.3},\n  mean: 0.84884, std: 0.01482, params: {'gamma': 0.4}],\n {'gamma': 0.2},\n 0.84990665772170337)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm3 = xgb.XGBClassifier(nthread=multiprocessing.cpu_count(),\n",
    "                         n_estimators=279,\n",
    "                         max_depth=7,\n",
    "                         min_child_weight=1)\n",
    "\n",
    "param_test3 = {\n",
    "    'gamma': [i/10.0 for i in range(0, 5)]\n",
    "}\n",
    "\n",
    "grid_search3 = grid_search(gbm3, param_test3)\n",
    "\n",
    "grid_search3.fit(X_train, y_train)\n",
    "grid_search3.grid_scores_, grid_search3.best_params_, grid_search3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score (Train): 0.985838\n"
     ]
    }
   ],
   "source": [
    "gbm_test = xgb.XGBClassifier(nthread=multiprocessing.cpu_count(),\n",
    "                             n_estimators=279,\n",
    "                             max_depth=7,\n",
    "                             min_child_weight=1,\n",
    "                             gamma=0.2)\n",
    "\n",
    "# Fit the algorithm on the data\n",
    "gbm_test.fit(X_train, y_train, eval_metric='auc')\n",
    "        \n",
    "# Predict training set:\n",
    "train_predict_prob = gbm_test.predict_proba(X_train)[:, 1]\n",
    "\n",
    "print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(y_train, train_predict_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until cv error hasn't decreased in 100 rounds.\nC:\\Program Files\\Python35\\lib\\site-packages\\xgboost-0.4-py3.5.egg\\xgboost\\training.py:270: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n  idset = [randidx[(i * kstep): min(len(randidx), (i + 1) * kstep)] for i in range(nfold)]\n[0]\tcv-test-auc:0.6416242000000001+0.012908669960921597\tcv-train-auc:0.6834988+0.01067304909386254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[500]\tcv-test-auc:0.8454118000000002+0.010237635242574346\tcv-train-auc:0.9971966+0.0001894735865496684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping. Best iteration:\n[523] cv-mean:0.8456368000000001\tcv-std:0.010235853855932082\n"
     ]
    }
   ],
   "source": [
    "gbm_test = xgb.XGBClassifier(nthread=multiprocessing.cpu_count(),\n",
    "                             n_estimators=1500,\n",
    "                             max_depth=7,\n",
    "                             min_child_weight=1,\n",
    "                             gamma=0.2)\n",
    "\n",
    "xg_train3 = xgb.DMatrix(X_train.values, label=y_train.values)\n",
    "cv_result3 = xgb.cv(gbm_test.get_params(), xg_train,\n",
    "                    num_boost_round=gbm.get_params()['n_estimators'],\n",
    "                    nfold=5, metrics=\"auc\",\n",
    "                    early_stopping_rounds=100,\n",
    "                    verbose_eval=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.84409, std: 0.00959, params: {'colsample_bytree': 0.3, 'subsample': 0.3},\n  mean: 0.84951, std: 0.00877, params: {'colsample_bytree': 0.3, 'subsample': 0.4},\n  mean: 0.85001, std: 0.01008, params: {'colsample_bytree': 0.3, 'subsample': 0.5},\n  mean: 0.85022, std: 0.00877, params: {'colsample_bytree': 0.3, 'subsample': 0.6},\n  mean: 0.85250, std: 0.00912, params: {'colsample_bytree': 0.3, 'subsample': 0.7},\n  mean: 0.85142, std: 0.01072, params: {'colsample_bytree': 0.3, 'subsample': 0.8},\n  mean: 0.85175, std: 0.01237, params: {'colsample_bytree': 0.3, 'subsample': 0.9},\n  mean: 0.84725, std: 0.00915, params: {'colsample_bytree': 0.3, 'subsample': 1.0},\n  mean: 0.84611, std: 0.00826, params: {'colsample_bytree': 0.4, 'subsample': 0.3},\n  mean: 0.85420, std: 0.00970, params: {'colsample_bytree': 0.4, 'subsample': 0.4},\n  mean: 0.85509, std: 0.00905, params: {'colsample_bytree': 0.4, 'subsample': 0.5},\n  mean: 0.85514, std: 0.01044, params: {'colsample_bytree': 0.4, 'subsample': 0.6},\n  mean: 0.85517, std: 0.00823, params: {'colsample_bytree': 0.4, 'subsample': 0.7},\n  mean: 0.85750, std: 0.00939, params: {'colsample_bytree': 0.4, 'subsample': 0.8},\n  mean: 0.85667, std: 0.01056, params: {'colsample_bytree': 0.4, 'subsample': 0.9},\n  mean: 0.85332, std: 0.00907, params: {'colsample_bytree': 0.4, 'subsample': 1.0},\n  mean: 0.84811, std: 0.00768, params: {'colsample_bytree': 0.5, 'subsample': 0.3},\n  mean: 0.85484, std: 0.00730, params: {'colsample_bytree': 0.5, 'subsample': 0.4},\n  mean: 0.85464, std: 0.01045, params: {'colsample_bytree': 0.5, 'subsample': 0.5},\n  mean: 0.85776, std: 0.00690, params: {'colsample_bytree': 0.5, 'subsample': 0.6},\n  mean: 0.85951, std: 0.00738, params: {'colsample_bytree': 0.5, 'subsample': 0.7},\n  mean: 0.85641, std: 0.00928, params: {'colsample_bytree': 0.5, 'subsample': 0.8},\n  mean: 0.85806, std: 0.01116, params: {'colsample_bytree': 0.5, 'subsample': 0.9},\n  mean: 0.85355, std: 0.01010, params: {'colsample_bytree': 0.5, 'subsample': 1.0},\n  mean: 0.84959, std: 0.00875, params: {'colsample_bytree': 0.6, 'subsample': 0.3},\n  mean: 0.85318, std: 0.01148, params: {'colsample_bytree': 0.6, 'subsample': 0.4},\n  mean: 0.85282, std: 0.01017, params: {'colsample_bytree': 0.6, 'subsample': 0.5},\n  mean: 0.85771, std: 0.01143, params: {'colsample_bytree': 0.6, 'subsample': 0.6},\n  mean: 0.85666, std: 0.00910, params: {'colsample_bytree': 0.6, 'subsample': 0.7},\n  mean: 0.85686, std: 0.00979, params: {'colsample_bytree': 0.6, 'subsample': 0.8},\n  mean: 0.85686, std: 0.01009, params: {'colsample_bytree': 0.6, 'subsample': 0.9},\n  mean: 0.85528, std: 0.01168, params: {'colsample_bytree': 0.6, 'subsample': 1.0},\n  mean: 0.84859, std: 0.00904, params: {'colsample_bytree': 0.7, 'subsample': 0.3},\n  mean: 0.84890, std: 0.01128, params: {'colsample_bytree': 0.7, 'subsample': 0.4},\n  mean: 0.85315, std: 0.00830, params: {'colsample_bytree': 0.7, 'subsample': 0.5},\n  mean: 0.85419, std: 0.01031, params: {'colsample_bytree': 0.7, 'subsample': 0.6},\n  mean: 0.85533, std: 0.01203, params: {'colsample_bytree': 0.7, 'subsample': 0.7},\n  mean: 0.85407, std: 0.01179, params: {'colsample_bytree': 0.7, 'subsample': 0.8},\n  mean: 0.85579, std: 0.01122, params: {'colsample_bytree': 0.7, 'subsample': 0.9},\n  mean: 0.85324, std: 0.01107, params: {'colsample_bytree': 0.7, 'subsample': 1.0},\n  mean: 0.84342, std: 0.00977, params: {'colsample_bytree': 0.8, 'subsample': 0.3},\n  mean: 0.84505, std: 0.01113, params: {'colsample_bytree': 0.8, 'subsample': 0.4},\n  mean: 0.85237, std: 0.01009, params: {'colsample_bytree': 0.8, 'subsample': 0.5},\n  mean: 0.85042, std: 0.01331, params: {'colsample_bytree': 0.8, 'subsample': 0.6},\n  mean: 0.85555, std: 0.01308, params: {'colsample_bytree': 0.8, 'subsample': 0.7},\n  mean: 0.85390, std: 0.00973, params: {'colsample_bytree': 0.8, 'subsample': 0.8},\n  mean: 0.85560, std: 0.01060, params: {'colsample_bytree': 0.8, 'subsample': 0.9},\n  mean: 0.85043, std: 0.01290, params: {'colsample_bytree': 0.8, 'subsample': 1.0},\n  mean: 0.84415, std: 0.01129, params: {'colsample_bytree': 0.9, 'subsample': 0.3},\n  mean: 0.84890, std: 0.01075, params: {'colsample_bytree': 0.9, 'subsample': 0.4},\n  mean: 0.85078, std: 0.01126, params: {'colsample_bytree': 0.9, 'subsample': 0.5},\n  mean: 0.85156, std: 0.01013, params: {'colsample_bytree': 0.9, 'subsample': 0.6},\n  mean: 0.85159, std: 0.01330, params: {'colsample_bytree': 0.9, 'subsample': 0.7},\n  mean: 0.85313, std: 0.01217, params: {'colsample_bytree': 0.9, 'subsample': 0.8},\n  mean: 0.85610, std: 0.01086, params: {'colsample_bytree': 0.9, 'subsample': 0.9},\n  mean: 0.85113, std: 0.01262, params: {'colsample_bytree': 0.9, 'subsample': 1.0},\n  mean: 0.84493, std: 0.01007, params: {'colsample_bytree': 1.0, 'subsample': 0.3},\n  mean: 0.84873, std: 0.01367, params: {'colsample_bytree': 1.0, 'subsample': 0.4},\n  mean: 0.85025, std: 0.01222, params: {'colsample_bytree': 1.0, 'subsample': 0.5},\n  mean: 0.84911, std: 0.00866, params: {'colsample_bytree': 1.0, 'subsample': 0.6},\n  mean: 0.85287, std: 0.01199, params: {'colsample_bytree': 1.0, 'subsample': 0.7},\n  mean: 0.85195, std: 0.01094, params: {'colsample_bytree': 1.0, 'subsample': 0.8},\n  mean: 0.85338, std: 0.01206, params: {'colsample_bytree': 1.0, 'subsample': 0.9},\n  mean: 0.84969, std: 0.01399, params: {'colsample_bytree': 1.0, 'subsample': 1.0}],\n {'colsample_bytree': 0.5, 'subsample': 0.7},\n 0.85950529717806867)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm4 = xgb.XGBClassifier(nthread=multiprocessing.cpu_count(),\n",
    "                         n_estimators=279,\n",
    "                         max_depth=7,\n",
    "                         min_child_weight=1)\n",
    "\n",
    "param_test4 = {\n",
    "    'subsample': [i/10.0 for i in range(3, 11)],\n",
    "    'colsample_bytree': [i/10.0 for i in range(3, 11)]\n",
    "}\n",
    "\n",
    "grid_search4 = grid_search(gbm4, param_test4)\n",
    "\n",
    "grid_search4.fit(X_train, y_train)\n",
    "grid_search4.grid_scores_, grid_search4.best_params_, grid_search4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until cv error hasn't decreased in 100 rounds.\nC:\\Program Files\\Python35\\lib\\site-packages\\xgboost-0.4-py3.5.egg\\xgboost\\training.py:270: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n  idset = [randidx[(i * kstep): min(len(randidx), (i + 1) * kstep)] for i in range(nfold)]\n[0]\tcv-test-auc:0.5997776+0.017198154419588173\tcv-train-auc:0.6239564+0.005930525123460827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score (Train): 0.979738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[500]\tcv-test-auc:0.855729+0.011887590369793182\tcv-train-auc:0.9951886+0.00018396369206993685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping. Best iteration:\n[609] cv-mean:0.8567316\tcv-std:0.012131000661116139\n"
     ]
    }
   ],
   "source": [
    "gbm_test = xgb.XGBClassifier(nthread=multiprocessing.cpu_count(),\n",
    "                             n_estimators=279,\n",
    "                             max_depth=7,\n",
    "                             min_child_weight=1,\n",
    "                             gamma=0.2,\n",
    "                             colsample_bytree=0.5,\n",
    "                             subsample=0.7)\n",
    "\n",
    "# Fit the algorithm on the data\n",
    "gbm_test.fit(X_train, y_train, eval_metric='auc')\n",
    "        \n",
    "# Predict training set:\n",
    "train_predict_prob = gbm_test.predict_proba(X_train)[:, 1]\n",
    "\n",
    "print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(y_train, train_predict_prob))\n",
    "\n",
    "gbm_test.n_estimators = 1500\n",
    "\n",
    "xg_train3 = xgb.DMatrix(X_train.values, label=y_train.values)\n",
    "cv_result3 = xgb.cv(gbm_test.get_params(), xg_train,\n",
    "                    num_boost_round=gbm.get_params()['n_estimators'],\n",
    "                    nfold=5, metrics=\"auc\",\n",
    "                    early_stopping_rounds=100,\n",
    "                    verbose_eval=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_final = xgb.XGBClassifier(nthread=multiprocessing.cpu_count(),\n",
    "                              n_estimators=279,\n",
    "                              max_depth=7,\n",
    "                              min_child_weight=1,\n",
    "                              gamma=0.2)\n",
    "\n",
    "gbm_final.fit(X_train, y_train, eval_metric='auc')\n",
    "\n",
    "predictions = gbm_final.predict(X_test)\n",
    "predict_prob = gbm_final.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y_test = predict_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.Series(data=y_test, name='Action', index=kagTestDat['id'])\n",
    "\n",
    "submission.to_csv(\"~/Documents/git/DataMining/submission_xgboost.csv\",\n",
    "                  index=True,\n",
    "                  sep=',',\n",
    "                  header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}